
# AI in the Real World: ChatGPT's Hallucinations  
*By leah Muchiri*  

## üß† What Happened?  
ChatGPT sometimes generates **false but convincing information**, such as:  
- Fabricated historical dates (*"The Mona Lisa was painted in 1815"*)  
- Fake academic papers (e.g., [this lawsuit](https://www.nytimes.com/2023/06/08/nyregion/lawyer-chatgpt-sanctions.html) where a lawyer cited non-existent cases)  

## ‚ö†Ô∏è Why It‚Äôs Problematic  
1. **Misinformation Spread**: Users trust ChatGPT‚Äôs authoritative tone.  
2. **No Built-in Uncertainty**: The bot rarely says "I don‚Äôt know."  
3. **Bias Amplification**: Errors often reflect gaps in training data.  

## üí° Improvement Idea  
**"Confidence Scoring + Citations"**  
- Add a **confidence meter** (e.g., "‚ö†Ô∏è 60% sure about this answer").  
- Require **source citations** for factual claims (like [Perplexity.ai](https://www.perplexity.ai/)).  

---
*Last updated: July 2024*  
